{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27e5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize and flatten data\n",
    "x_train_flat = x_train.reshape(len(x_train), 28*28) / 255.0\n",
    "x_test_flat = x_test.reshape(len(x_test), 28*28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73073153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yugesh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build model's architecture \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9447cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7950 - loss: 0.6452 - val_accuracy: 0.9584 - val_loss: 0.1404\n",
      "Epoch 2/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1827 - val_accuracy: 0.9734 - val_loss: 0.0935\n",
      "Epoch 3/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1391 - val_accuracy: 0.9728 - val_loss: 0.0916\n",
      "Epoch 4/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.1200 - val_accuracy: 0.9740 - val_loss: 0.0931\n",
      "Epoch 5/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0975 - val_accuracy: 0.9782 - val_loss: 0.0770\n",
      "Epoch 6/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.0914 - val_accuracy: 0.9793 - val_loss: 0.0732\n",
      "Epoch 7/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.0814 - val_accuracy: 0.9791 - val_loss: 0.0736\n",
      "Epoch 8/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0751 - val_accuracy: 0.9805 - val_loss: 0.0685\n",
      "Epoch 9/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0720 - val_accuracy: 0.9796 - val_loss: 0.0745\n",
      "Epoch 10/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0689 - val_accuracy: 0.9808 - val_loss: 0.0692\n",
      "Epoch 11/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0642 - val_accuracy: 0.9808 - val_loss: 0.0723\n",
      "Epoch 12/12\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0618 - val_accuracy: 0.9815 - val_loss: 0.0661\n",
      "Final test accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "# Train with more epochs\n",
    "model.fit(x_train_flat, y_train, \n",
    "            epochs=12, \n",
    "            batch_size=32,\n",
    "            validation_data=(x_test_flat, y_test),\n",
    "            verbose=1)\n",
    "\n",
    "# Test accuracy\n",
    "test_loss, test_acc = model.evaluate(x_test_flat, y_test, verbose=0)\n",
    "print(f\"Final test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49167f70",
   "metadata": {},
   "source": [
    "### Try to predict with a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f00e5dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x183c8ff2e70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(x_test[82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d61e8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = x_test_flat[82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f61c50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "image_array = np.array(image_data, dtype=np.float32).reshape(28, 28)\n",
    "# Reshape for model input\n",
    "image_array = image_array.reshape(1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2838f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 2, Confidence: 100.0%\n",
      "All probabilities: ['0.000', '0.000', '1.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000']\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "predictions = model.predict(image_array, verbose=0)\n",
    "predicted_digit = int(np.argmax(predictions[0]))\n",
    "confidence = float(np.max(predictions[0]) * 100)\n",
    "\n",
    "print(f\"Predicted: {predicted_digit}, Confidence: {confidence:.1f}%\")\n",
    "print(f\"All probabilities: {[f'{p:.3f}' for p in predictions[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b891ae8",
   "metadata": {},
   "source": [
    "The above model is sufficient for basic predictions since the dataset was specifically designed for this task. However, in real-world scenarios, additional preprocessing is often required before feeding data into the model to achieve more accurate and reliable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1, 784)\n",
      "Image min/max: 0.000/0.990\n",
      "Predicted: 0, Confidence: 100.0%\n",
      "All probabilities: ['1.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000', '0.000']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Center the digit using center of mass\n",
    "if np.sum(image_array) > 0:\n",
    "    # Find center of mass\n",
    "    y_coords, x_coords = np.where(image_array > 0.1)\n",
    "    if len(x_coords) > 0 and len(y_coords) > 0:\n",
    "        center_x = int(np.mean(x_coords))\n",
    "        center_y = int(np.mean(y_coords))\n",
    "        \n",
    "        # Calculate shift to center (14,14 is center of 28x28)\n",
    "        shift_x = 14 - center_x\n",
    "        shift_y = 14 - center_y\n",
    "        \n",
    "        # Create centered image\n",
    "        centered_image = np.zeros((28, 28))\n",
    "        for y in range(28):\n",
    "            for x in range(28):\n",
    "                new_y = y - shift_y\n",
    "                new_x = x - shift_x\n",
    "                if 0 <= new_y < 28 and 0 <= new_x < 28:\n",
    "                    centered_image[y, x] = image_array[new_y, new_x]\n",
    "        \n",
    "        image_array = centered_image\n",
    "\n",
    "# Normalize intensity\n",
    "if np.max(image_array) > 0:\n",
    "    image_array = image_array / np.max(image_array)\n",
    "\n",
    "# Apply slight Gaussian blur for smoothing\n",
    "from scipy.ndimage import gaussian_filter\n",
    "image_array = gaussian_filter(image_array, sigma=0.5)\n",
    "\n",
    "# Reshape for model input\n",
    "image_array = image_array.reshape(1, 784)\n",
    "\n",
    "print(f\"Image shape: {image_array.shape}\")\n",
    "print(f\"Image min/max: {image_array.min():.3f}/{image_array.max():.3f}\")\n",
    "\n",
    "# Make prediction\n",
    "predictions = model.predict(image_array, verbose=0)\n",
    "predicted_digit = int(np.argmax(predictions[0]))\n",
    "confidence = float(np.max(predictions[0]) * 100)\n",
    "\n",
    "print(f\"Predicted: {predicted_digit}, Confidence: {confidence:.1f}%\")\n",
    "print(f\"All probabilities: {[f'{p:.3f}' for p in predictions[0]]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
